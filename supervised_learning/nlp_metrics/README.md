# Natural Language Processing - Evaluation Metrics

## Overview

This project provides an exploration of various evaluation metrics used in Natural Language Processing (NLP) to assess the performance of models. Key metrics include BLEU, ROUGE, and perplexity.

## Features

- **BLEU Score**: Measures the precision of machine translation outputs.
- **ROUGE Score**: Evaluates summarization quality based on recall and precision.
- **Perplexity**: Assesses language models by measuring uncertainty in predictions.

## Requirements

- Python 3.x
- Required libraries: `nltk`, `scikit-learn`, `numpy`, etc.